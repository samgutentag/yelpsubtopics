{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review Data EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from glob import glob\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_marker(text=''):\n",
    "    print('[{}] {}'.format(datetime.datetime.now().time(), text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "import matplotlib\n",
    "font = {'size' : 50}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "TITLE_FONT_SIZE = 25\n",
    "LABEL_FONT_SIZE = 15\n",
    "TICK_FONT_SIZE  = 15\n",
    "\n",
    "FIG_SIZE = (15,6)\n",
    "DO_WRITE_CHARTS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Review Data for Arizona Restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:21:25.556042] Loading Review Data...\n",
      "[17:21:25.558329] Reading 1 of 1 ../clean_data/az_restaurant_reviews.csv...\n",
      "[17:21:34.320888] merging to dataframe...\n",
      "[17:21:35.500623] reseting index...\n",
      "[17:21:35.510243] Complete!\n"
     ]
    }
   ],
   "source": [
    "time_marker(text='Loading Review Data...')\n",
    "\n",
    "reviews = pd.DataFrame()\n",
    "file_path_slug = '../clean_data/az_restaurant_reviews.csv'\n",
    "file_list = glob(file_path_slug)\n",
    "\n",
    "# Chunk Settings\n",
    "chunks = list()\n",
    "chunksize = 10000\n",
    "for ii, file in enumerate(sorted(file_list)):\n",
    "    time_marker('Reading {} of {} {}...'.format(ii+1, len(file_list), file))\n",
    "    # import file in chunks\n",
    "    for jj, chunk in enumerate(pd.read_csv(file, chunksize=chunksize, iterator=True, index_col=0, parse_dates=['date'])):\n",
    "        \n",
    "        # append chunk to chunks list\n",
    "        chunks.append(chunk)\n",
    "        \n",
    "time_marker(text='merging to dataframe...')\n",
    "reviews = pd.concat(chunks)\n",
    "\n",
    "time_marker('reseting index...')\n",
    "reviews.reset_index(inplace=True, drop=True)\n",
    "time_marker(text='Complete!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:21:37.006823] Dropping records with NaN values...\n",
      "[17:21:37.805531] Cleaning data types...\n",
      "[17:21:38.362676] assiging 'Positive' or 'Negative' classification to reviews...\n"
     ]
    }
   ],
   "source": [
    "time_marker('Dropping records with NaN values...')\n",
    "reviews.dropna(how='any', inplace=True)\n",
    "reviews.reset_index(inplace=True, drop=True)\n",
    "\n",
    "time_marker('Cleaning data types...')\n",
    "reviews['cool'] = reviews['cool'].astype('int')\n",
    "reviews['funny'] = reviews['funny'].astype('int')\n",
    "reviews['stars'] = reviews['stars'].astype('int')\n",
    "reviews['useful'] = reviews['useful'].astype('int')\n",
    "reviews['review_len'] = reviews['review_len'].astype('int')\n",
    "reviews['is_fast_food'] = reviews['is_fast_food'].apply(lambda x: True if x == 1 else False)\n",
    "reviews['date'] = pd.to_datetime(reviews['date'])\n",
    "\n",
    "time_marker('assiging \\'Positive\\' or \\'Negative\\' classification to reviews...')\n",
    "reviews['is_positive'] = reviews.stars.apply(lambda x: True if x > 3 else False)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 495893 entries, 0 to 495892\n",
      "Data columns (total 12 columns):\n",
      "business_id     495893 non-null object\n",
      "cool            495893 non-null int64\n",
      "date            495893 non-null datetime64[ns]\n",
      "funny           495893 non-null int64\n",
      "review_id       495893 non-null object\n",
      "stars           495893 non-null int64\n",
      "text            495893 non-null object\n",
      "useful          495893 non-null int64\n",
      "user_id         495893 non-null object\n",
      "is_fast_food    495893 non-null bool\n",
      "review_len      495893 non-null int64\n",
      "is_positive     495893 non-null bool\n",
      "dtypes: bool(2), datetime64[ns](1), int64(5), object(4)\n",
      "memory usage: 38.8+ MB\n"
     ]
    }
   ],
   "source": [
    "reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_fast_food</th>\n",
       "      <th>review_len</th>\n",
       "      <th>is_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JlNeaOymdVbE6_bubqjohg</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-08-09</td>\n",
       "      <td>0</td>\n",
       "      <td>BF0ANB54sc_f-3_howQBCg</td>\n",
       "      <td>1</td>\n",
       "      <td>we always go to the chevo's in chandler which ...</td>\n",
       "      <td>3</td>\n",
       "      <td>ssuXFjkH4neiBgwv-oN4IA</td>\n",
       "      <td>False</td>\n",
       "      <td>422</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0Rni7ocMC_Lg2UH0lDeKMQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-08-09</td>\n",
       "      <td>0</td>\n",
       "      <td>DbLUpPT61ykLTakknCF9CQ</td>\n",
       "      <td>1</td>\n",
       "      <td>this place is always so dirty and grimy been t...</td>\n",
       "      <td>6</td>\n",
       "      <td>ssuXFjkH4neiBgwv-oN4IA</td>\n",
       "      <td>False</td>\n",
       "      <td>111</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S-oLPRdhlyL5HAknBKTUcQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11-30</td>\n",
       "      <td>0</td>\n",
       "      <td>z_mVLygzPn8uHp63SSCErw</td>\n",
       "      <td>4</td>\n",
       "      <td>holy portion sizes! you get a lot of bang for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>MzEnYCyZlRYQRISNMXTWIg</td>\n",
       "      <td>False</td>\n",
       "      <td>130</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cool       date  funny               review_id  \\\n",
       "0  JlNeaOymdVbE6_bubqjohg     0 2014-08-09      0  BF0ANB54sc_f-3_howQBCg   \n",
       "1  0Rni7ocMC_Lg2UH0lDeKMQ     0 2014-08-09      0  DbLUpPT61ykLTakknCF9CQ   \n",
       "2  S-oLPRdhlyL5HAknBKTUcQ     0 2017-11-30      0  z_mVLygzPn8uHp63SSCErw   \n",
       "\n",
       "   stars                                               text  useful  \\\n",
       "0      1  we always go to the chevo's in chandler which ...       3   \n",
       "1      1  this place is always so dirty and grimy been t...       6   \n",
       "2      4  holy portion sizes! you get a lot of bang for ...       0   \n",
       "\n",
       "                  user_id  is_fast_food  review_len  is_positive  \n",
       "0  ssuXFjkH4neiBgwv-oN4IA         False         422        False  \n",
       "1  ssuXFjkH4neiBgwv-oN4IA         False         111        False  \n",
       "2  MzEnYCyZlRYQRISNMXTWIg         False         130         True  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Review Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# terms and characters to ignore, we dont care about punctuation\n",
    "exclude = set(string.punctuation)\n",
    "\n",
    "contractions = [\"'s\", \"n't\", \"'ll\", \"'t\", \"'s\", \"'re\"]\n",
    "\n",
    "# lemma\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "exclusion_terms = list(set(set(stop_words) | set(exclude) | set(contractions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_review(doc):\n",
    "    ''' remove stop words, remove punctuation, and lemmatize a text document'''\n",
    "\n",
    "    # lemmatize, tokenize and remove stop words, puncuation and contractions\n",
    "    # remove non alpha tokens\n",
    "    tokens = [lemma.lemmatize(word) for word in word_tokenize(doc) if word not in exclusion_terms and word.isalpha()]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Review Corpus for LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "from collections import defaultdict\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_prep(corpus=None, n_terms=5):\n",
    "    '''\n",
    "    \n",
    "        @ params:\n",
    "            corpus   : a list of \n",
    "            n_terms  : the number of top terms to preview to the console\n",
    "    \n",
    "        returns:\n",
    "            a list of 3 items\n",
    "                dictionary        :  a gensim dictionary object built from the corpus\n",
    "                corpus            :  a bag of words sparce array of corpus terms\n",
    "                total_word_count  :  a defaultdict with key word identifier in dictionary, and value the count of times that word appears in the corpus\n",
    "    \n",
    "    '''\n",
    "    if corpus == None:\n",
    "        return False  \n",
    "    else:\n",
    "        time_marker('building gensim dict...')\n",
    "        # build gensim dict, key=token, value=count\n",
    "        dictionary = Dictionary(corpus)\n",
    "        # print('dictionary Tokens to ID {}'.format(dictionary.token2id))\n",
    "\n",
    "        # create a gensim corpus\n",
    "        time_marker('building gensim corpus...')\n",
    "        corpus = [dictionary.doc2bow(doc) for doc in clean_docs]\n",
    "        # print('gensim Corpus {}'.format(corpus[0]))\n",
    "\n",
    "        # create a defaultdict\n",
    "        total_word_count = defaultdict(int)\n",
    "\n",
    "        # loop over corpus and count the number of times each word appears\n",
    "        for word_id, word_count in itertools.chain.from_iterable(corpus):\n",
    "            total_word_count[word_id] += word_count\n",
    "\n",
    "        # create a sorted list from the defaultdict\n",
    "        sorted_word_count = sorted(total_word_count.items(), key=lambda w: w[1], reverse=True)\n",
    "\n",
    "        # print top n_terms words across all documents\n",
    "        print('Top {:d} words across all documents'.format(n_terms))\n",
    "        for word_id, word_count in sorted_word_count[:n_terms]:\n",
    "            print('{:20}{}'.format(dictionary.get(word_id), word_count))\n",
    "        \n",
    "        return [dictionary, corpus, total_word_count]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split up by `Fast Food` and `Non Fast Food` Restaurant Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_reviews = reviews[reviews.is_fast_food == True].copy()\n",
    "ff_reviews.reset_index(inplace=True, drop=True)\n",
    "nff_reviews = reviews[reviews.is_fast_food == False].copy()\n",
    "nff_reviews.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================== Fast Food Reviews ==============================\n",
      "Number of Fast Food Reviews                  39907\t8.0475\n",
      "Number of Positive Fast Food Reviews         19488\t48.8335\n",
      "Number of Negative Fast Food Reviews         20419\t51.1665\n",
      "\n",
      "============================ Non Fast Food Reviews ============================\n",
      "Number of Non Fast Food Reviews              455986\t91.9525\n",
      "Number of Positive Non Fast Food Reviews     303285\t66.5119\n",
      "Number of Negative Non Fast Food Reviews     152701\t33.4881\n"
     ]
    }
   ],
   "source": [
    "print('============================== Fast Food Reviews ==============================')\n",
    "print('{:45}{:d}\\t{:2.4f}'.format('Number of Fast Food Reviews', ff_reviews.shape[0], 100.*ff_reviews.shape[0] / reviews.shape[0]))\n",
    "print('{:45}{:d}\\t{:2.4f}'.format('Number of Positive Fast Food Reviews', ff_reviews[ff_reviews.is_positive == True].shape[0], (100.*ff_reviews[ff_reviews.is_positive == True].shape[0]/ff_reviews.shape[0])))\n",
    "print('{:45}{:d}\\t{:2.4f}'.format('Number of Negative Fast Food Reviews', ff_reviews[ff_reviews.is_positive == False].shape[0], (100.*ff_reviews[ff_reviews.is_positive == False].shape[0]/ff_reviews.shape[0])))\n",
    "\n",
    "print()\n",
    "print('============================ Non Fast Food Reviews ============================')\n",
    "print('{:45}{:d}\\t{:2.4f}'.format('Number of Non Fast Food Reviews', nff_reviews.shape[0], 100.*nff_reviews.shape[0] / reviews.shape[0]))\n",
    "print('{:45}{:d}\\t{:2.4f}'.format('Number of Positive Non Fast Food Reviews', nff_reviews[nff_reviews.is_positive == True].shape[0], (100.*nff_reviews[nff_reviews.is_positive == True].shape[0]/nff_reviews.shape[0])))\n",
    "print('{:45}{:d}\\t{:2.4f}'.format('Number of Negative Non Fast Food Reviews', nff_reviews[nff_reviews.is_positive == False].shape[0], (100.*nff_reviews[nff_reviews.is_positive == False].shape[0]/nff_reviews.shape[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast Food Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Step 1: </b>Subset to only evaluate `Fast Food` Reviews</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_fast_food</th>\n",
       "      <th>review_len</th>\n",
       "      <th>is_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iIjVO7cLD1UEmIO7G05Ujw</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-06-11</td>\n",
       "      <td>0</td>\n",
       "      <td>xatycgntu_F_Ioyny3iflw</td>\n",
       "      <td>4</td>\n",
       "      <td>flavor was actually pretty good. not used to e...</td>\n",
       "      <td>0</td>\n",
       "      <td>vaXJ7-xLrnD6FAEhUqYKwQ</td>\n",
       "      <td>True</td>\n",
       "      <td>309</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8F-CalsRSKiPjjsx8ql8Lg</td>\n",
       "      <td>9</td>\n",
       "      <td>2009-12-22</td>\n",
       "      <td>8</td>\n",
       "      <td>xWvUUQ-tO-x9pAsG8JEnOQ</td>\n",
       "      <td>4</td>\n",
       "      <td>i really want to give this place four stars. g...</td>\n",
       "      <td>6</td>\n",
       "      <td>dyhTHLIf6eWBvU78Y3T06A</td>\n",
       "      <td>True</td>\n",
       "      <td>2349</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>W2CzAePJakvARgoQuohbOA</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-08-30</td>\n",
       "      <td>0</td>\n",
       "      <td>B9Eq_4FSMD4zCfCDiEXazQ</td>\n",
       "      <td>5</td>\n",
       "      <td>times have changed. unfortunately i am no long...</td>\n",
       "      <td>0</td>\n",
       "      <td>Jt4u7qnfrk35buainfOuGA</td>\n",
       "      <td>True</td>\n",
       "      <td>468</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cool       date  funny               review_id  \\\n",
       "0  iIjVO7cLD1UEmIO7G05Ujw     0 2016-06-11      0  xatycgntu_F_Ioyny3iflw   \n",
       "1  8F-CalsRSKiPjjsx8ql8Lg     9 2009-12-22      8  xWvUUQ-tO-x9pAsG8JEnOQ   \n",
       "6  W2CzAePJakvARgoQuohbOA     0 2011-08-30      0  B9Eq_4FSMD4zCfCDiEXazQ   \n",
       "\n",
       "   stars                                               text  useful  \\\n",
       "0      4  flavor was actually pretty good. not used to e...       0   \n",
       "1      4  i really want to give this place four stars. g...       6   \n",
       "6      5  times have changed. unfortunately i am no long...       0   \n",
       "\n",
       "                  user_id  is_fast_food  review_len  is_positive  \n",
       "0  vaXJ7-xLrnD6FAEhUqYKwQ          True         309         True  \n",
       "1  dyhTHLIf6eWBvU78Y3T06A          True        2349         True  \n",
       "6  Jt4u7qnfrk35buainfOuGA          True         468         True  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff_reviews.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19488"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff_reviews.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Step 2: </b>Tokenize and Normalize review text</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:30:47.209000] tokenizing and normalizing text...\n",
      "[17:31:22.268828] done!\n"
     ]
    }
   ],
   "source": [
    "time_marker('tokenizing and normalizing text...')\n",
    "ff_reviews['tokens'] = ff_reviews.text.apply(lambda r: clean_review(r))\n",
    "ff_reviews['norm_text'] = ff_reviews.tokens.apply(lambda t: ' '.join(t))\n",
    "time_marker('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>business_id</th>\n",
       "      <td>iIjVO7cLD1UEmIO7G05Ujw</td>\n",
       "      <td>8F-CalsRSKiPjjsx8ql8Lg</td>\n",
       "      <td>W2CzAePJakvARgoQuohbOA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cool</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>2016-06-11 00:00:00</td>\n",
       "      <td>2009-12-22 00:00:00</td>\n",
       "      <td>2011-08-30 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funny</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_id</th>\n",
       "      <td>xatycgntu_F_Ioyny3iflw</td>\n",
       "      <td>xWvUUQ-tO-x9pAsG8JEnOQ</td>\n",
       "      <td>B9Eq_4FSMD4zCfCDiEXazQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stars</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>flavor was actually pretty good. not used to e...</td>\n",
       "      <td>i really want to give this place four stars. g...</td>\n",
       "      <td>times have changed. unfortunately i am no long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>useful</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <td>vaXJ7-xLrnD6FAEhUqYKwQ</td>\n",
       "      <td>dyhTHLIf6eWBvU78Y3T06A</td>\n",
       "      <td>Jt4u7qnfrk35buainfOuGA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_fast_food</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_len</th>\n",
       "      <td>309</td>\n",
       "      <td>2349</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_positive</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>[flavor, actually, pretty, good, used, eating,...</td>\n",
       "      <td>[really, want, give, place, four, star, greg, ...</td>\n",
       "      <td>[time, changed, unfortunately, longer, sun, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>norm_text</th>\n",
       "      <td>flavor actually pretty good used eating menudo...</td>\n",
       "      <td>really want give place four star greg would st...</td>\n",
       "      <td>time changed unfortunately longer sun devil cl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              0  \\\n",
       "business_id                              iIjVO7cLD1UEmIO7G05Ujw   \n",
       "cool                                                          0   \n",
       "date                                        2016-06-11 00:00:00   \n",
       "funny                                                         0   \n",
       "review_id                                xatycgntu_F_Ioyny3iflw   \n",
       "stars                                                         4   \n",
       "text          flavor was actually pretty good. not used to e...   \n",
       "useful                                                        0   \n",
       "user_id                                  vaXJ7-xLrnD6FAEhUqYKwQ   \n",
       "is_fast_food                                               True   \n",
       "review_len                                                  309   \n",
       "is_positive                                                True   \n",
       "tokens        [flavor, actually, pretty, good, used, eating,...   \n",
       "norm_text     flavor actually pretty good used eating menudo...   \n",
       "\n",
       "                                                              1  \\\n",
       "business_id                              8F-CalsRSKiPjjsx8ql8Lg   \n",
       "cool                                                          9   \n",
       "date                                        2009-12-22 00:00:00   \n",
       "funny                                                         8   \n",
       "review_id                                xWvUUQ-tO-x9pAsG8JEnOQ   \n",
       "stars                                                         4   \n",
       "text          i really want to give this place four stars. g...   \n",
       "useful                                                        6   \n",
       "user_id                                  dyhTHLIf6eWBvU78Y3T06A   \n",
       "is_fast_food                                               True   \n",
       "review_len                                                 2349   \n",
       "is_positive                                                True   \n",
       "tokens        [really, want, give, place, four, star, greg, ...   \n",
       "norm_text     really want give place four star greg would st...   \n",
       "\n",
       "                                                              6  \n",
       "business_id                              W2CzAePJakvARgoQuohbOA  \n",
       "cool                                                          0  \n",
       "date                                        2011-08-30 00:00:00  \n",
       "funny                                                         0  \n",
       "review_id                                B9Eq_4FSMD4zCfCDiEXazQ  \n",
       "stars                                                         5  \n",
       "text          times have changed. unfortunately i am no long...  \n",
       "useful                                                        0  \n",
       "user_id                                  Jt4u7qnfrk35buainfOuGA  \n",
       "is_fast_food                                               True  \n",
       "review_len                                                  468  \n",
       "is_positive                                                True  \n",
       "tokens        [time, changed, unfortunately, longer, sun, de...  \n",
       "norm_text     time changed unfortunately longer sun devil cl...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff_reviews.head(3).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Step 3: </b>Build our term dictionary, document term matrix, and preview the most common terms</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:16:51.263525] building gensim dict...\n",
      "[18:16:51.350837] building gensim corpus...\n",
      "Top 25 words across all documents\n",
      "food                636\n",
      "place               553\n",
      "good                530\n",
      "great               461\n",
      "burger              357\n",
      "always              342\n",
      "get                 328\n",
      "service             313\n",
      "like                312\n",
      "time                295\n",
      "love                272\n",
      "one                 271\n",
      "fry                 257\n",
      "friendly            250\n",
      "fast                241\n",
      "go                  236\n",
      "order               232\n",
      "location            231\n",
      "back                227\n",
      "pizza               205\n",
      "sandwich            197\n",
      "really              187\n",
      "staff               187\n",
      "fresh               179\n",
      "delicious           171\n"
     ]
    }
   ],
   "source": [
    "# collect all cleaned review strings into a list of strings\n",
    "clean_docs = list(ff_reviews.tokens[:1000].values)\n",
    "\n",
    "# create dictionary, corpus, and word counts with custom function\n",
    "dictionary, doc_term_matrix, total_word_count = lda_prep(corpus=clean_docs, n_terms=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Step 4: </b>Using a Multicore LDA model, attempt to identify topics from the dictionary</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "ldam = LdaMulticore\n",
    "\n",
    "num_topics = 50\n",
    "num_words  = 10\n",
    "num_passes = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:16:53.233327] started generating lda multicore model\n",
      "[18:24:26.656576] done!\n"
     ]
    }
   ],
   "source": [
    "time_marker('started generating lda multicore model')\n",
    "ldam_model = ldam(doc_term_matrix, num_topics=num_topics, id2word=dictionary, passes=num_passes)\n",
    "time_marker('done!')\n",
    "\n",
    "results = ldam_model.print_topics(num_topics=num_topics, num_words=num_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Step 6: </b>View Results</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print Model Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topic_terms(model, num_topics=num_topics, num_words=10, unique=False):\n",
    "    results = model.print_topics(num_topics=num_topics, num_words=num_words)\n",
    "    if not unique:\n",
    "        print('=============================== Terms Per Topic ===============================')\n",
    "        for r in results:\n",
    "            topic = r[0]\n",
    "            term_list = r[1]\n",
    "\n",
    "            term_list = term_list.split('\"')[1::2]\n",
    "            topic_terms = [term for term in term_list]\n",
    "            print('{}\\t{}'.format(topic, topic_terms))\n",
    "    else:\n",
    "        terms = [x[1] for x in results]\n",
    "        term_lists = [x.split('\"')[1::2] for x in terms]\n",
    "\n",
    "        flatList = itertools.chain.from_iterable(term_lists)\n",
    "        term_counts = Counter(flatList)\n",
    "\n",
    "        # non_unique_terms = term_counts\n",
    "        test = dict(term_counts)\n",
    "\n",
    "        # extract terms that appear more than once\n",
    "        non_unique_terms = [key for key, value in test.items() if value > 1]\n",
    "        \n",
    "        \n",
    "        print('============================ Unique Terms Per Topic ===========================')\n",
    "        for r in results:\n",
    "            topic = r[0]\n",
    "            term_list = r[1]\n",
    "\n",
    "            term_list = term_list.split('\"')[1::2]\n",
    "            topic_terms = [term for term in term_list if term not in non_unique_terms]\n",
    "            print('{}\\t{}'.format(topic, topic_terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================== Terms Per Topic ===============================\n",
      "0\t['food', 'good', 'place', 'sandwich', 'like', 'fry', 'burger', 'would', 'one', 'fast']\n",
      "1\t['food', 'order', 'little', 'delicious', 'also', 'fry', 'much', 'place', 'one', 'get']\n",
      "2\t['dog', 'hot', 'chicago', 'beef', 'good', 'sandwich', 'place', 'chili', 'fry', 'try']\n",
      "3\t['fish', 'place', 'chip', 'n', 'time', 'food', 'go', 'year', 'always', 'good']\n",
      "4\t['chicken', 'good', 'get', 'eat', 'place', 'like', 'usually', 'love', 'enjoy', 'wing']\n",
      "5\t['wait', 'food', 'incredible', 'service', 'long', 'great', 'well', 'ca', 'restaurant', 'night']\n",
      "6\t['good', 'place', 'food', 'one', 'really', 'go', 'chicken', 'like', 'better', 'restaurant']\n",
      "7\t['coney', 'detroit', 'great', 'dog', 'good', 'place', 'go', 'owner', 'fry', 'say']\n",
      "8\t['burger', 'u', 'food', 'back', 'got', 'time', 'one', 'mcdonald', 'nice', 'fast']\n",
      "9\t['glad', 'fast', 'food', 'breakfast', 'english', 'fish', 'u', 'chang', 'plate', 'place']\n",
      "10\t['taco', 'delicious', 'place', 'found', 'food', 'really', 'good', 'try', 'go', 'pizza']\n",
      "11\t['place', 'burger', 'love', 'great', 'get', 'clean', 'good', 'food', 'friendly', 'always']\n",
      "12\t['like', 'order', 'loved', 'made', 'sandwich', 'wanted', 'one', 'burger', 'cheese', 'fry']\n",
      "13\t['burger', 'time', 'fry', 'food', 'order', 'good', 'back', 'got', 'always', 'lobby']\n",
      "14\t['food', 'like', 'place', 'always', 'fast', 'good', 'three', 'meal', 'meat', 'extra']\n",
      "15\t['dog', 'cheese', 'place', 'one', 'time', 'try', 'burger', 'first', 'crust', 'delicious']\n",
      "16\t['place', 'great', 'burger', 'time', 'try', 'always', 'nice', 'favorite', 'never', 'want']\n",
      "17\t['burger', 'get', 'always', 'love', 'never', 'go', 'would', 'fry', 'two', 'try']\n",
      "18\t['burger', 'dog', 'get', 'place', 'would', 'try', 'fry', 'u', 'inside', 'though']\n",
      "19\t['place', 'good', 'could', 'back', 'food', 'chicken', 'lunch', 'burger', 'fry', 'little']\n",
      "20\t['sub', 'mike', 'sandwich', 'subway', 'firehouse', 'jersey', 'love', 'get', 'new', 'pizza']\n",
      "21\t['love', 'good', 'food', 'taco', 'time', 'delicious', 'also', 'like', 'choice', 'meat']\n",
      "22\t['sandwich', 'one', 'great', 'place', 'food', 'like', 'friendly', 'time', 'burger', 'location']\n",
      "23\t['pizza', 'great', 'good', 'topping', 'place', 'crust', 'price', 'awesome', 'love', 'like']\n",
      "24\t['chicken', 'order', 'location', 'one', 'inch', 'wrap', 'right', 'bell', 'know', 'goodcents']\n",
      "25\t['always', 'food', 'place', 'good', 'get', 'kid', 'love', 'never', 'time', 'friendly']\n",
      "26\t['get', 'good', 'food', 'review', 'fry', 'burger', 'great', 'like', 'price', 'one']\n",
      "27\t['sandwich', 'great', 'place', 'love', 'lunch', 'back', 'five', 'clean', 'guy', 'food']\n",
      "28\t['delicious', 'food', 'drive', 'burrito', 'breakfast', 'order', 'made', 'right', 'still', 'quickly']\n",
      "29\t['place', 'breakfast', 'burrito', 'sandwich', 'simple', 'great', 'nice', 'open', 'try', 'real']\n",
      "30\t['good', 'waffle', 'enough', 'pretty', 'poutine', 'great', 'well', 'cheese', 'much', 'yes']\n",
      "31\t['food', 'like', 'make', 'burger', 'always', 'back', 'great', 'well', 'fresh', 'lunch']\n",
      "32\t['good', 'pollo', 'salad', 'el', 'chicken', 'love', 'bean', 'burger', 'secret', 'price']\n",
      "33\t['place', 'lot', 'like', 'burger', 'wendy', 'back', 'awesome', 'tasty', 'good', 'great']\n",
      "34\t['great', 'get', 'food', 'burger', 'fry', 'good', 'also', 'place', 'fast', 'menu']\n",
      "35\t['good', 'place', 'food', 'chinese', 'like', 'go', 'really', 'fresh', 'rice', 'order']\n",
      "36\t['taco', 'burrito', 'carne', 'asada', 'salsa', 'bean', 'place', 'cheese', 'good', 'rice']\n",
      "37\t['pizza', 'place', 'great', 'time', 'home', 'back', 'lot', 'like', 'definitely', 'sure']\n",
      "38\t['food', 'always', 'service', 'great', 'location', 'friendly', 'fast', 'staff', 'good', 'get']\n",
      "39\t['delicious', 'definitely', 'green', 'cheese', 'sample', 'got', 'back', 'really', 'place', 'taco']\n",
      "40\t['pizza', 'place', 'delicious', 'food', 'amazing', 'new', 'staff', 'back', 'friendly', 'definitely']\n",
      "41\t['one', 'food', 'delicious', 'take', 'husband', 'good', 'also', 'lunch', 'time', 'love']\n",
      "42\t['place', 'back', 'really', 'great', 'family', 'fry', 'like', 'lunch', 'kid', 'meat']\n",
      "43\t['place', 'food', 'fast', 'meal', 'delicious', 'go', 'back', 'could', 'love', 'service']\n",
      "44\t['burger', 'love', 'get', 'place', 'delicious', 'service', 'excellent', 'time', 'good', 'fast']\n",
      "45\t['got', 'back', 'like', 'employee', 'customer', 'sure', 'make', 'good', 'great', 'really']\n",
      "46\t['great', 'food', 'place', 'service', 'price', 'pizza', 'highly', 'back', 'reasonable', 'time']\n",
      "47\t['burger', 'fry', 'like', 'get', 'good', 'place', 'fast', 'order', 'time', 'food']\n",
      "48\t['order', 'u', 'get', 'dish', 'party', 'waited', 'even', 'fry', 'bell', 'always']\n",
      "49\t['food', 'review', 'fast', 'fry', 'good', 'nice', 'service', 'bread', 'really', 'experience']\n"
     ]
    }
   ],
   "source": [
    "print_topic_terms(ldam_model, num_topics=num_topics, num_words=10, unique=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================ Unique Terms Per Topic ===========================\n",
      "0\t[]\n",
      "1\t[]\n",
      "2\t['hot', 'chicago', 'beef', 'chili']\n",
      "3\t['chip', 'n', 'year']\n",
      "4\t['eat', 'usually', 'enjoy', 'wing']\n",
      "5\t['wait', 'incredible', 'long', 'ca', 'night']\n",
      "6\t['better']\n",
      "7\t['coney', 'detroit', 'owner', 'say']\n",
      "8\t['mcdonald']\n",
      "9\t['glad', 'english', 'chang', 'plate']\n",
      "10\t['found']\n",
      "11\t[]\n",
      "12\t['loved', 'wanted']\n",
      "13\t['lobby']\n",
      "14\t['three', 'extra']\n",
      "15\t['first']\n",
      "16\t['favorite', 'want']\n",
      "17\t['two']\n",
      "18\t['inside', 'though']\n",
      "19\t[]\n",
      "20\t['sub', 'mike', 'subway', 'firehouse', 'jersey']\n",
      "21\t['choice']\n",
      "22\t[]\n",
      "23\t['topping']\n",
      "24\t['inch', 'wrap', 'know', 'goodcents']\n",
      "25\t[]\n",
      "26\t[]\n",
      "27\t['five', 'guy']\n",
      "28\t['drive', 'still', 'quickly']\n",
      "29\t['simple', 'open', 'real']\n",
      "30\t['waffle', 'enough', 'pretty', 'poutine', 'yes']\n",
      "31\t[]\n",
      "32\t['pollo', 'salad', 'el', 'secret']\n",
      "33\t['wendy', 'tasty']\n",
      "34\t['menu']\n",
      "35\t['chinese']\n",
      "36\t['carne', 'asada', 'salsa']\n",
      "37\t['home']\n",
      "38\t[]\n",
      "39\t['green', 'sample']\n",
      "40\t['amazing']\n",
      "41\t['take', 'husband']\n",
      "42\t['family']\n",
      "43\t[]\n",
      "44\t['excellent']\n",
      "45\t['employee', 'customer']\n",
      "46\t['highly', 'reasonable']\n",
      "47\t[]\n",
      "48\t['dish', 'party', 'waited', 'even']\n",
      "49\t['bread', 'experience']\n"
     ]
    }
   ],
   "source": [
    "print_topic_terms(ldam_model, num_topics=num_topics, num_words=10, unique=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to disk (no need to use pickle module)\n",
    "term = 'test'\n",
    "file_suffix = '{}_{:d}_topics_{:d}_terms_{}_passes'.format(term, num_topics, num_words, num_passes)\n",
    "ldam_model.save('../models/ldam_{}.model'.format(file_suffix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
